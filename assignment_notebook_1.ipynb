{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8e649671-64ae-4692-a381-33974ffa666a",
      "metadata": {
        "id": "8e649671-64ae-4692-a381-33974ffa666a"
      },
      "source": [
        "# Assignment 3\n",
        "## Econ 8310 - Business Forecasting\n",
        "\n",
        "For homework assignment 3, you will work with [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist), a more fancier data set.\n",
        "\n",
        "- You must create a custom data loader as described in the first week of neural network lectures [2 points]\n",
        "    - You will NOT receive credit for this if you use the pytorch prebuilt loader for Fashion MNIST!\n",
        "- You must create a working and trained neural network using only pytorch [2 points]\n",
        "- You must store your weights and create an import script so that I can evaluate your model without training it [2 points]\n",
        "\n",
        "Highest accuracy score gets some extra credit!\n",
        "\n",
        "Submit your forked repository URL on Canvas! :) I'll be manually grading this assignment.\n",
        "\n",
        "Some checks you can make on your own:\n",
        "- Did you manually process the data or use a prebuilt loader (see above)?\n",
        "- Does your script train a neural network on the assigned data?\n",
        "- Did your script save your model?\n",
        "- Do you have separate code to import your model for use after training?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bcd35387-b05b-4cb2-9b1f-e1d2c0e43588",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcd35387-b05b-4cb2-9b1f-e1d2c0e43588",
        "outputId": "cbddf4d3-65f0-42bd-b46c-1eceae30c1b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Training Loss: 0.5928\n",
            "Epoch 2 | Training Loss: 0.4182\n",
            "Epoch 3 | Training Loss: 0.3819\n",
            "Epoch 4 | Training Loss: 0.3590\n",
            "Epoch 5 | Training Loss: 0.3431\n",
            "Epoch 6 | Training Loss: 0.3337\n",
            "Epoch 7 | Training Loss: 0.3232\n",
            "Epoch 8 | Training Loss: 0.3110\n",
            "Epoch 9 | Training Loss: 0.3064\n",
            "Epoch 10 | Training Loss: 0.2999\n",
            "Model saved successfully as 'saved_fmnist_model.pth'.\n",
            "Final Test Accuracy: 88.00%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import gzip\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import urllib.request\n",
        "\n",
        "# Fetch Fashion MNIST files manually\n",
        "def fetch_fashion_data():\n",
        "    url = \"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/\"\n",
        "    file_dict = {\n",
        "        \"train_img\": \"train-images-idx3-ubyte.gz\",\n",
        "        \"train_lbl\": \"train-labels-idx1-ubyte.gz\",\n",
        "        \"test_img\": \"t10k-images-idx3-ubyte.gz\",\n",
        "        \"test_lbl\": \"t10k-labels-idx1-ubyte.gz\"\n",
        "    }\n",
        "    os.makedirs(\"data\", exist_ok=True)\n",
        "    for key, filename in file_dict.items():\n",
        "        path = os.path.join(\"data\", filename)\n",
        "        if not os.path.isfile(path):\n",
        "            urllib.request.urlretrieve(url + filename, path)\n",
        "\n",
        "# Load image data\n",
        "def parse_images(filepath):\n",
        "    with gzip.open(filepath, 'rb') as f:\n",
        "        f.read(16)\n",
        "        images = np.frombuffer(f.read(), dtype=np.uint8).reshape(-1, 28*28)\n",
        "    return images.astype(np.float32) / 255.0\n",
        "\n",
        "# Load label data\n",
        "def parse_labels(filepath):\n",
        "    with gzip.open(filepath, 'rb') as f:\n",
        "        f.read(8)\n",
        "        return np.frombuffer(f.read(), dtype=np.uint8)\n",
        "\n",
        "# Custom Dataset class\n",
        "class FMNISTDataset(Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.X = torch.tensor(images)\n",
        "        self.Y = torch.tensor(labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.Y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.Y[idx]\n",
        "\n",
        "# MLP Neural Network\n",
        "class FashionClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(784, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "def train_and_save():\n",
        "    fetch_fashion_data()\n",
        "    x_train = parse_images(\"data/train-images-idx3-ubyte.gz\")\n",
        "    y_train = parse_labels(\"data/train-labels-idx1-ubyte.gz\")\n",
        "    x_test = parse_images(\"data/t10k-images-idx3-ubyte.gz\")\n",
        "    y_test = parse_labels(\"data/t10k-labels-idx1-ubyte.gz\")\n",
        "\n",
        "    train_data = FMNISTDataset(x_train, y_train)\n",
        "    test_data = FMNISTDataset(x_test, y_test)\n",
        "\n",
        "    train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_data, batch_size=64)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = FashionClassifier().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for ep in range(1, 11):\n",
        "        model.train()\n",
        "        cumulative_loss = 0\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            preds = model(xb)\n",
        "            loss = criterion(preds, yb)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            cumulative_loss += loss.item()\n",
        "        print(f\"Epoch {ep} | Training Loss: {cumulative_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    torch.save(model.state_dict(), \"saved_fmnist_model.pth\")\n",
        "    print(\"Model saved successfully as 'saved_fmnist_model.pth'.\")\n",
        "\n",
        "    # Accuracy on test data\n",
        "    model.eval()\n",
        "    total, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in test_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            out = model(xb)\n",
        "            _, predicted = torch.max(out, 1)\n",
        "            correct += (predicted == yb).sum().item()\n",
        "            total += yb.size(0)\n",
        "\n",
        "    print(f\"Final Test Accuracy: {100 * correct / total:.2f}%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_and_save()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gzip\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Load image data\n",
        "def parse_images(filepath):\n",
        "    with gzip.open(filepath, 'rb') as f:\n",
        "        f.read(16)\n",
        "        images = np.frombuffer(f.read(), dtype=np.uint8).reshape(-1, 28*28)\n",
        "    return images.astype(np.float32) / 255.0\n",
        "\n",
        "# Load label data\n",
        "def parse_labels(filepath):\n",
        "    with gzip.open(filepath, 'rb') as f:\n",
        "        f.read(8)\n",
        "        return np.frombuffer(f.read(), dtype=np.uint8)\n",
        "\n",
        "# Custom Dataset class\n",
        "class FMNISTDataset(Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.X = torch.tensor(images)\n",
        "        self.Y = torch.tensor(labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.Y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.Y[idx]\n",
        "\n",
        "# Same model structure as training\n",
        "class FashionClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(784, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "def load_and_evaluate():\n",
        "    x_test = parse_images(\"data/t10k-images-idx3-ubyte.gz\")\n",
        "    y_test = parse_labels(\"data/t10k-labels-idx1-ubyte.gz\")\n",
        "    test_data = FMNISTDataset(x_test, y_test)\n",
        "    test_loader = DataLoader(test_data, batch_size=64)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = FashionClassifier().to(device)\n",
        "    model.load_state_dict(torch.load(\"saved_fmnist_model.pth\", map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    total, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in test_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            preds = model(xb)\n",
        "            _, predicted = torch.max(preds, 1)\n",
        "            correct += (predicted == yb).sum().item()\n",
        "            total += yb.size(0)\n",
        "\n",
        "    print(f\"Test Accuracy (loaded model): {100 * correct / total:.2f}%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    load_and_evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJHZMX7wCOVi",
        "outputId": "e38a2856-f00d-4840-e27a-c5fc4a3c5d48"
      },
      "id": "RJHZMX7wCOVi",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy (loaded model): 88.00%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}